{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "W2-xE_fvYDo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "519825c4-7490-4536-8c83-5dadf041a02a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting isic-cli\n",
            "  Downloading isic_cli-12.4.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: click>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from isic-cli) (8.3.1)\n",
            "Collecting django-s3-file-field-client>=1.0.0 (from isic-cli)\n",
            "  Downloading django_s3_file_field_client-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting girder-cli-oauth-client<1.0.0 (from isic-cli)\n",
            "  Downloading girder_cli_oauth_client-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from isic-cli) (4.14.0)\n",
            "Collecting isic-metadata>=1.2.0 (from isic-cli)\n",
            "  Downloading isic_metadata-4.11.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from isic-cli) (10.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from isic-cli) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from isic-cli) (2.32.4)\n",
            "Collecting retryable-requests (from isic-cli)\n",
            "  Downloading retryable_requests-0.1.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from isic-cli) (13.9.4)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.12/dist-packages (from isic-cli) (2.45.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.12/dist-packages (from isic-cli) (8.5.0)\n",
            "Requirement already satisfied: authlib in /usr/local/lib/python3.12/dist-packages (from girder-cli-oauth-client<1.0.0->isic-cli) (1.6.5)\n",
            "Collecting pyxdg (from girder-cli-oauth-client<1.0.0->isic-cli)\n",
            "  Downloading pyxdg-0.28-py2.py3-none-any.whl.metadata (567 bytes)\n",
            "Requirement already satisfied: pydantic>=2.4 in /usr/local/lib/python3.12/dist-packages (from isic-metadata>=1.2.0->isic-cli) (2.11.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->isic-cli) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->isic-cli) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->isic-cli) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->isic-cli) (2025.11.12)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from retryable-requests->isic-cli) (1.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->isic-cli) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->isic-cli) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->isic-cli) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.4->isic-metadata>=1.2.0->isic-cli) (0.4.2)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from authlib->girder-cli-oauth-client<1.0.0->isic-cli) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography->authlib->girder-cli-oauth-client<1.0.0->isic-cli) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography->authlib->girder-cli-oauth-client<1.0.0->isic-cli) (2.23)\n",
            "Downloading isic_cli-12.4.0-py3-none-any.whl (34 kB)\n",
            "Downloading django_s3_file_field_client-1.1.0-py3-none-any.whl (3.2 kB)\n",
            "Downloading girder_cli_oauth_client-0.4.0-py3-none-any.whl (8.1 kB)\n",
            "Downloading isic_metadata-4.11.0-py3-none-any.whl (27 kB)\n",
            "Downloading retryable_requests-0.1.2-py3-none-any.whl (7.5 kB)\n",
            "Downloading pyxdg-0.28-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyxdg, django-s3-file-field-client, retryable-requests, isic-metadata, girder-cli-oauth-client, isic-cli\n",
            "Successfully installed django-s3-file-field-client-1.1.0 girder-cli-oauth-client-0.4.0 isic-cli-12.4.0 isic-metadata-4.11.0 pyxdg-0.28 retryable-requests-0.1.2\n"
          ]
        }
      ],
      "source": [
        "# Instala la herramienta Consola del archivo ISIC\n",
        "!pip install isic-cli #Sacada desde el repositorio de Github https://github.com/ImageMarkup/isic-cli/blob/master/README.md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7uZCtRsYT51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d6e64b-3a47-4dd5-d659-bad6fc39c674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you have been granted special permissions, logging in with `isic user login` might return more data.\n",
            "\n",
            "\u001b[2KDownloading images + metadata (25,331 files, 2.7 GB) \u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "\u001b[32mSuccessfully downloaded 25,331 images to Training2019/.\u001b[0m\n",
            "\u001b[32mSuccessfully wrote 25,331 metadata records to Training2019/metadata.csv.\u001b[0m\n",
            "\u001b[32mSuccessfully wrote attributions to Training2019/attribution.txt.\u001b[0m\n",
            "\u001b[32mSuccessfully wrote 2 license(s) to Training2019/licenses.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#Testeado y funcionando\n",
        "!isic image download --search \"\" --collections \"65\" --limit 0 Training2019/ # Imagenes y Metadatos de Entrenamiento Año 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "ZlWsbuSr3FsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def cargar_metadatos(archivo):\n",
        "    \"\"\"\n",
        "    Carga los metadatos desde un archivo CSV y filtra las imágenes con diagnóstico Benign (0) y Malignant (1).\n",
        "    Retorna un diccionario con isic_id y las etiquetas mapeadas a 0 y 1.\n",
        "    \"\"\"\n",
        "    datos = {\n",
        "        'isic_id': [],\n",
        "        'diagnosis_1': []  # Las etiquetas serán 0 o 1\n",
        "    }\n",
        "    etiquetas_validas = {'Benign': 0, 'Malignant': 1}  # Mapeamos las etiquetas a 0 y 1\n",
        "\n",
        "    try:\n",
        "        with open(archivo, 'r', encoding='utf-8') as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)  # Evita las columnas cabeceras.\n",
        "\n",
        "            diagnosis_idx =9  # Cambiar al índice correspondiente si es necesario\n",
        "            #7 para BCN20000\n",
        "            # 9 para training2019\n",
        "            for fila in reader:\n",
        "                if len(fila) > diagnosis_idx:\n",
        "                    diagnosis = fila[diagnosis_idx]\n",
        "                    if diagnosis in etiquetas_validas:  # Solo almacenar Benign y Malignant\n",
        "                        datos['isic_id'].append(fila[0])  # Almacena el ID de la imagen\n",
        "                        datos['diagnosis_1'].append(etiquetas_validas[diagnosis])  # Asignamos la etiqueta 0 o 1\n",
        "\n",
        "        print(f\"Datos extraídos y filtrados correctamente. Se encontraron {len(datos['isic_id'])} registros válidos.\")\n",
        "        return datos\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Archivo {archivo} no encontrado\")\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "KwsgwC-K2_TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "# Se elimina: from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "def organizar_imagenes_en_carpetas(carpeta_origen, metadatos, carpeta_destino_base):\n",
        "    \"\"\"\n",
        "    Organiza el 100% de las imágenes en carpetas 'test' según su clase.\n",
        "    \"\"\"\n",
        "    # --- 1. Crear las carpetas de destino ---\n",
        "    # El loop solo crea el directorio 'test'\n",
        "    for split in ['test']:\n",
        "        for class_name in ['benign', 'malignant']:\n",
        "            os.makedirs(os.path.join(carpeta_destino_base, split, class_name), exist_ok=True)\n",
        "\n",
        "    # --- 2. Separar los IDs por clase ---\n",
        "    ids_benignos = []\n",
        "    ids_malignos = []\n",
        "    for id_img, etiqueta in zip(metadatos['isic_id'], metadatos['diagnosis_1']):\n",
        "        if etiqueta == 0:  # Benign\n",
        "            ids_benignos.append(id_img)\n",
        "        elif etiqueta == 1: # Malignant\n",
        "            ids_malignos.append(id_img)\n",
        "\n",
        "    # --- 3. Asignar el 100% de los IDs al conjunto de 'test' ---\n",
        "    # [Lógica: Modificación solicitada]\n",
        "    # No se usa train_test_split para enviar todo a 'test'.\n",
        "    # Se asigna la lista completa de IDs de cada clase.\n",
        "    ids_benignos_test = ids_benignos\n",
        "    ids_malignos_test = ids_malignos\n",
        "\n",
        "    # --- 4. Función auxiliar para copiar archivos ---\n",
        "    def copiar_archivos(ids, carpeta_destino):\n",
        "        for id_img in tqdm(ids, desc=f'Copiando a {os.path.basename(os.path.normpath(carpeta_destino))}'):\n",
        "            nombre_archivo = f\"{id_img}.jpg\"\n",
        "            ruta_origen = os.path.join(carpeta_origen, nombre_archivo)\n",
        "            ruta_destino = os.path.join(carpeta_destino, nombre_archivo)\n",
        "            if os.path.exists(ruta_origen):\n",
        "                shutil.copy(ruta_origen, ruta_destino)\n",
        "            else:\n",
        "                # [Mejor Práctica]: Es preferible usar 'warning' o 'logging'\n",
        "                print(f\"Advertencia: No se encontró el archivo {ruta_origen}\")\n",
        "\n",
        "    # --- 5. Copiar los archivos a sus directorios finales ---\n",
        "\n",
        "    print(\"Copiando imágenes de prueba benignas...\")\n",
        "    copiar_archivos(ids_benignos_test, os.path.join(carpeta_destino_base, 'test', 'benign'))\n",
        "\n",
        "    print(\"Copiando imágenes de prueba malignas...\")\n",
        "    copiar_archivos(ids_malignos_test, os.path.join(carpeta_destino_base, 'test', 'malignant'))\n",
        "\n",
        "    # Se actualiza el mensaje final para reflejar la acción\n",
        "    print(f\"\\nEl 100% de las imágenes ({len(ids_benignos_test) + len(ids_malignos_test)} archivos) se ha organizado correctamente en la carpeta 'test'.\")"
      ],
      "metadata": {
        "id": "xt6kWiHE3E8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Eliminar el directorio del dataset antiguo para evitar conflictos y asegurar una regeneración limpia\n",
        "if os.path.exists('/content/dataset'):\n",
        "    shutil.rmtree('/content/dataset')\n",
        "    print(\"Directorio '/content/dataset' anterior eliminado.\")\n",
        "else:\n",
        "    print(\"El directorio '/content/dataset' no existía, no fue necesaria ninguna limpieza.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDcRQFHq3oOH",
        "outputId": "241ed539-3a33-4ec2-f146-81e8af0b24a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El directorio '/content/dataset' no existía, no fue necesaria ninguna limpieza.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Asumiendo que los metadatos ya han sido cargados correctamente\n",
        "metadatos = cargar_metadatos(\"/content/Training2019/metadata.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR2qej3K3RpM",
        "outputId": "4db495ee-9873-47cf-ac6d-302a115c9006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos extraídos y filtrados correctamente. Se encontraron 24463 registros válidos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "organizar_imagenes_en_carpetas('/content/Training2019/', metadatos, '/content/dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWOVQxRx3XSV",
        "outputId": "b55a615d-28f5-4e82-a18a-df709ba613b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copiando imágenes de prueba benignas...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copiando a benign: 100%|██████████| 15990/15990 [00:10<00:00, 1565.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copiando imágenes de prueba malignas...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copiando a malignant: 100%|██████████| 8473/8473 [00:06<00:00, 1231.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El 100% de las imágenes (24463 archivos) se ha organizado correctamente en la carpeta 'test'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def crear_generador_para_inferencia(carpeta_test, batch_size=32, target_size=(224, 224)):\n",
        "\n",
        "    # Definición del Generador\n",
        "    # que se usó en el entrenamiento (en este caso, el rescalado).\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "    # mantengan el orden de los archivos.\n",
        "    inference_generator = test_datagen.flow_from_directory(\n",
        "        carpeta_test,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='sparse',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    print(f\"Generador de inferencia creado. Apuntando a: {carpeta_test}\")\n",
        "    print(f\"Imágenes encontradas: {inference_generator.n}\")\n",
        "\n",
        "    # Se retorna tanto la configuración (datagen) como el iterador (flow)\n",
        "    return test_datagen, inference_generator\n",
        "\n",
        "RUTA_TEST = '/content/dataset/test'\n",
        "\n",
        "# batch_size=1 para predicciones individuales\n",
        "datagen_inferencia, generador_inferencia = crear_generador_para_inferencia(\n",
        "    RUTA_TEST,\n",
        "    batch_size=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQtQqN7E6Yxs",
        "outputId": "b452079c-8cce-4538-8238-f1d27a3ab17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 24463 images belonging to 2 classes.\n",
            "Generador de inferencia creado. Apuntando a: /content/dataset/test\n",
            "Imágenes encontradas: 24463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf_keras tensorflow_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgXsabRPWhuM",
        "outputId": "5366275f-e186-44ba-c28d-665c18849c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_keras in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.12/dist-packages (0.16.1)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19 in /usr/local/lib/python3.12/dist-packages (from tf_keras) (2.19.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow_hub) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow_hub) (5.29.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (25.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf_keras) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tf_keras\n",
        "import numpy as np\n",
        "\n",
        "# Rutas\n",
        "MODEL_PATH = \"/content/model_v1.h5\"\n",
        "\n",
        "print(f\"Cargando modelo legacy desde {MODEL_PATH}...\")\n",
        "\n",
        "try:\n",
        "    # Definir objetos personalizados\n",
        "    custom_objects_dict = {\n",
        "        'KerasLayer': hub.KerasLayer,\n",
        "        'TrueDivide': tf.math.truediv\n",
        "    }\n",
        "\n",
        "    model = tf_keras.models.load_model(MODEL_PATH, custom_objects=custom_objects_dict)\n",
        "\n",
        "    print(\"Modelo cargado exitosamente con tf_keras.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error fatal al cargar: {e}\")\n",
        "    raise\n",
        "\n",
        "# Realizando Inferencia\n",
        "print(\"Realizando predicciones (inferencia)...\")\n",
        "\n",
        "y_pred_proba = model.predict(\n",
        "    generador_inferencia,\n",
        "    steps=generador_inferencia.n,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Inferencia completada. Se obtuvieron {len(y_pred_proba)} predicciones.\")\n",
        "print(\"\\n--- Celda 2 Ejecutada ---\")"
      ],
      "metadata": {
        "id": "sdSHeSd799q0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff51190e-c114-4237-8a2c-41b76b5b89eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando modelo legacy desde /content/model_v1.h5...\n",
            "✅ Modelo cargado exitosamente con tf_keras.\n",
            "Realizando predicciones (inferencia)...\n",
            "24463/24463 [==============================] - 2348s 96ms/step\n",
            "Inferencia completada. Se obtuvieron 24463 predicciones.\n",
            "\n",
            "--- Celda 2 Ejecutada ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "CSV_OUTPUT_PATH = \"resultados_validacion_ModeloTL.csv\"\n",
        "EXCEL_OUTPUT_PATH = \"resultados_validacion_ModeloTL.xlsx\"\n",
        "\n",
        "\n",
        "# Procesar Predicciones y Datos Reales\n",
        "print(\"Procesando resultados de la inferencia...\")\n",
        "\n",
        "# Convertir probabilidades a etiquetas (0 o 1)\n",
        "# np.argmax encuentra el índice (0 o 1) con la probabilidad más alta\n",
        "y_pred_labels = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "# Obtener la probabilidad (confianza) de la predicción\n",
        "y_pred_scores = np.max(y_pred_proba, axis=1)\n",
        "\n",
        "y_true_labels = generador_inferencia.classes\n",
        "filenames = generador_inferencia.filenames\n",
        "\n",
        "# Ensamble del DataFrame\n",
        "print(\"Ensamblando DataFrame...\")\n",
        "\n",
        "# Crear un mapa para convertir 0 -> 'benign', 1 -> 'malignant'\n",
        "label_map = {v: k for k, v in generador_inferencia.class_indices.items()}\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'nombre_imagen': [os.path.basename(f) for f in filenames],\n",
        "    'diagnostico_original_id': y_true_labels,\n",
        "    'diagnostico_propuesto_id': y_pred_labels,\n",
        "    'confianza_prediccion': y_pred_scores\n",
        "})\n",
        "\n",
        "# Mapear los IDs a nombres legibles\n",
        "df['diagnostico_original'] = df['diagnostico_original_id'].map(label_map)\n",
        "df['diagnostico_propuesto'] = df['diagnostico_propuesto_id'].map(label_map)\n",
        "\n",
        "# Seleccionar y ordenar las columnas finales\n",
        "df_final = df[[\n",
        "    'nombre_imagen',\n",
        "    'diagnostico_original',\n",
        "    'diagnostico_propuesto',\n",
        "    'confianza_prediccion'\n",
        "]]\n",
        "\n",
        "# Guardar en Archivos\n",
        "try:\n",
        "    # Guardar en CSV\n",
        "    df_final.to_csv(CSV_OUTPUT_PATH, index=False, encoding='utf-8')\n",
        "    print(f\"\\n¡Éxito! Resultados guardados en {CSV_OUTPUT_PATH}\")\n",
        "\n",
        "    # Guardar en Excel\n",
        "    df_final.to_excel(EXCEL_OUTPUT_PATH, index=False)\n",
        "    print(f\"¡Éxito! Resultados convertidos a Excel y guardados en {EXCEL_OUTPUT_PATH}\")\n",
        "\n",
        "    # Mostrar las primeras 5 filas\n",
        "    print(\"\\nPrimeras 5 filas del resultado:\")\n",
        "    print(df_final.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar los archivos de resultados: {e}\")\n",
        "\n",
        "print(\"\\n--- Celda 3 Ejecutada ---\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hXYoEW6A-Ovh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641a8c82-339b-4881-c88a-809a07f25b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando resultados de la inferencia...\n",
            "Ensamblando DataFrame...\n",
            "\n",
            "¡Éxito! Resultados guardados en resultados_validacion_ModeloTL.csv\n",
            "¡Éxito! Resultados convertidos a Excel y guardados en resultados_validacion_ModeloTL.xlsx\n",
            "\n",
            "Primeras 5 filas del resultado:\n",
            "      nombre_imagen diagnostico_original diagnostico_propuesto  \\\n",
            "0  ISIC_0000000.jpg               benign                benign   \n",
            "1  ISIC_0000001.jpg               benign                benign   \n",
            "2  ISIC_0000003.jpg               benign                benign   \n",
            "3  ISIC_0000006.jpg               benign                benign   \n",
            "4  ISIC_0000007.jpg               benign                benign   \n",
            "\n",
            "   confianza_prediccion  \n",
            "0              0.809904  \n",
            "1              0.939729  \n",
            "2              0.908125  \n",
            "3              0.715470  \n",
            "4              0.819043  \n",
            "\n",
            "--- Celda 3 Ejecutada ---\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}